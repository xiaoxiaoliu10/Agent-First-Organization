
<!-- saved from url=(0036)https://www.cs.columbia.edu/~zhouyu/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <link rel="stylesheet" href="./www.cs.columbia.edu_files/css">
  <link rel="stylesheet" type="text/css" data-href="dynamic-stylesheet" href="./www.cs.columbia.edu_files/main.css">
<style type="text/css">

<!--

body {
	font: 100%/1.4 Verdana, Arial, Helvetica, sans-serif;

	/*background: #42413C;*/
	margin: 0;
	padding: 0;
	color: #000;
	/*background-color: #069;*/
}

#app {
	height: 100vh;
}

#app {
    /* ~~ 元素/标签选择器 ~~ */
    ul, ol, dl {
        /* 由于浏览器之间的差异，最佳做法是在列表中将填充和边距都设置为零。 */
        padding: 0;
        margin: 0;
    }

    h1, h2, h3, h4, h5, h6, p {
        margin-top: 10px; /* 删除上边距可以解决边距会超出其包含的 div 的问题。 */
        padding-right: 50px;
        padding-left: 100px; /* 向 div 内的元素侧边添加填充可避免使用任何方框模型数学。 */
    }

    a img {
        /* 此选择器将删除某些浏览器中显示在图像周围的默认蓝色边框 */
        border: none;
    }

    /* ~~ 站点链接的样式必须保持此顺序，包括用于创建悬停效果的选择器组在内。 ~~ */
    a:link {
        color: #42413C;
        text-decoration: underline;
    }

    a:visited {
        color: #6E6C64;
        text-decoration: underline;
    }

    a:hover, a:active, a:focus {
        /* 此组选择器将为键盘导航者提供与鼠标使用者相同的悬停体验。 */
        text-decoration: none;
    }

    /* ~~ 此固定宽度容器包含所有其它 div ~~ */
    .container {
        width: 1000px;
        background: #FFF;
        margin: 0 auto;
        overflow: hidden;
    }

    /* ~~ 以下是此布局的列。 ~~ */
    .content {
        padding: 0px 0;
        width: 1000px;
        float: middle;
    }

    /* ~~ 此分组的选择器为 .content 区域中的列表提供了空间 ~~ */
    .content ul, .content ol {
        padding: 0 15px 15px 40px;
    }

    /* ~~ 导航列表样式 ~~ */
    ul.nav {
        list-style: none;
        border-top: 1px solid #666;
        margin-bottom: 15px;
    }

    ul.nav li {
        border-bottom: 1px solid #666;
    }

    ul.nav a, ul.nav a:visited {
        padding: 5px 5px 5px 15px;
        display: block;
        width: 120px;
        text-decoration: none;
        background: #C6D580;
    }

    ul.nav a:hover, ul.nav a:active, ul.nav a:focus {
        background: #ADB96E;
        color: #FFF;
    }

    /* ~~ 其它浮动/清除类 ~~ */
    .fltrt {
        float: right;
        margin-left: 10px;
    }

    .fltlft {
        float: left;
        margin-right: 0px;
    }

    .clearfloat {
        clear: both;
        height: 0;
        font-size: 1px;
        line-height: 0px;
    }

    .papertitle {
        color: #000080;
    }
}

-->

</style><script charset="utf-8" src="./www.cs.columbia.edu_files/button.856debeac157d9669cf51e73a08fbc93.js"></script></head>


<body>

<div id="app">
<div class="container">
<div class="content"> 
    <table border="0" cellpadding="0" cellspacing="0">
    <tbody><tr><td width="250" align="middle">
     <p class="style2"><img alt="" height="343.3" src="./www.cs.columbia.edu_files/007.jpg" width="344.9"></p>
    </td>
    <td width="450" height="240" align="left">
          <h2>Zhou Yu &nbsp;  俞舟</h2>
	<p>Zhou (pronunced similar to Jo)</p>
        <p></p>
	<p>Associate Professor</p>
	<p>Computer Science Department</p>
        <p>Columbia University</p>
        <p>Address:</p>
	<p>Schapiro CEPSR 723</p>
        <p>530 West 120th Street, New York, NY 10027</p>
	<p>Email: <a href="mailto:zy2461@columbia.edu">zy2461@columbia.edu</a></p>
	<p><a href="https://www.linkedin.com/in/zhou-jo-yu-95327378" target="_blank">
    <img src="./www.cs.columbia.edu_files/LinkedIn_logo_initials.png" alt="LinkedIn Profile" width="40" height="40">
</a></p>
	<p><iframe id="twitter-widget-0" scrolling="no" frameborder="0" allowtransparency="true" allowfullscreen="true" class="twitter-follow-button twitter-follow-button-rendered" title="Twitter Follow Button" src="./www.cs.columbia.edu_files/follow_button.2f70fb173b9000da126c79afe2098f02.en.html" style="position: static; visibility: visible; width: 156px; height: 20px;" data-screen-name="Zhou_Yu_AI"></iframe><script async="" src="./www.cs.columbia.edu_files/widgets.js" charset="utf-8"></script>
</p><p>CV <a href="https://drive.google.com/file/d/10-nTl4BJzbo9yoyKbT6cR9lih-1P74tE/view?usp=sharing">[pdf]</a> </p>
</td>
    </tr></tbody></table>
<hr>

<h3><font color="orange">Welcome </font></h3>

   <p>I am an Associate Professor at the Computer Science Department, Columbia University. I am also a co-founder of <a href="https://www.arklex.ai/">Arklex.ai</a> that centers its efforts on harnessing the power of AI Agents to empower and shape the future landscape of the workspace. Before that I was an Assistant Professor at UC Davis. I received my PhD at Language Technology Institute under School of Computer Science, Carnegie Mellon University 2017, working with <a href="http://www.cs.cmu.edu/~awb/"> Prof. Alan W Black </a> and <a href="http://www.cs.cmu.edu/~air/"> Prof. Alexander I. Rudnicky</a>. 2015 summer and 2016 summer, I interned with <a href="http://suendermann.com/su/index.htm/l">Prof. David Suendermann-Oeft </a> at ETS San Francisco Office on cloud based multimodal dialog systems. 2014 Fall, I interned with <a href="http://research.microsoft.com/en-us/um/people/dbohus/">Dan Bohus </a> and <a href="http://research.microsoft.com/en-us/um/people/horvitz/"> Eric Horvitz </a> at Microsoft Research on situated multimodal dialogue systems. I was featured on Forbes 30 under 30 in Science in 2018. My team also won the 2018 Amazon Alexa Socialbot Competition. Our work on Persuasive Dialog Systems also won ACL 2019 best paper nomination.</p>
<p>Prior to CMU, I received a B.S. in Computer Science and a B.A. in Linguistics under English Language Major from Zhejiang University in 2011. I worked with Prof. Xiaofei He and Prof. Deng Cai on Machine Learning and Computer Vision. I also worked with Prof. Yunhua Qu on Machine Translation.</p><hr>
<h3><font color="orange">Research Interests</font></h3>
<!--/*<p>My research aims to leverage automatic obtainable multimodal information with machine learning methods to make conversations more nature and effective. The dynamics of both verbal and nonverbal behaviors of the conversational parties contribute to the process and outcome of the conversation. In order to understand human-human and human-dialog system interactions and improve the underlying model of the system, I design methods to predict conversation partners' attention and engagement in real time using both verbal and nonverbal behaviors, such as gaze and smiles. Then I leverage these signals to change system's conversatioanl strategies on the fly to accomendate users.</p>*/-->
<p>I design algorithms for real-time <b>intelligent interactive systems </b> that coordinate with user actions that are beyond spoken languages, including non-verbal behaviors to achieve effective and natural communications. In particular, I optimize human-machine communication via studies of <b>multimodal sensing and analysis</b>, <b>speech and natural language processing</b>, <b>machine learning</b> and <b>human-computer interaction</b>. The central focus of my dissertation research is to bring together all the areas above to design, implement and deploy end-to-end real-time interactive intelligent systems that are able to plan globally considering interaction history and current user actions to achieve better user experience and task performance. Meanwhile, I enjoy collaborating with researchers with different backgrounds on interdisciplinary research in all area of science, such as health care, education and robotics. </p>

<hr> 
<h3><font color="orange"> Talks </font></h3>
<p>This is the teaching material of my COM 4705 Introduction to Natural Language Processing 2024 Fall <a href="https://docs.google.com/document/d/1hBrfzdk6Xjp_7ct-1M23tkm0IbPi9x_z5RvuHGPaEEM/edit?tab=t.0">Webpage</a></p>
<p>I generally recruite PhDs and interns every year, so don't send me generic email to ask about it. If you don't have much experience, please follow this <a href="https://www.linkedin.com/posts/zhou-jo-yu-95327378_this-is-the-time-of-year-when-my-inboxes-activity-7273367390971641857-Ex3O?utm_source=share&amp;utm_medium=member_desktop"> LinkedIn post</a> to get in contact.</p>
<p>We just released our Open-Source AI Agent framework with features such as mixed-control, task composition, human-intervention and continual learning, want to know more, please check <a href="https://arklexai.github.io/Agent-First-Organization/">here</a></p>
<p>Our recent work, <a href="https://agent-e3.github.io/ExACT/">ExACT</a> on AI Agent planning is the top entry on various AI Agent Benchmark. Check it our, open source code coming soon </p>
<p>Slides from my rescent talk: AI Agents beyond ChatGPT <a href="https://docs.google.com/presentation/d/1mFA4fVSX1viMO0sq-YHeihTQN46PELGok2m-ibzwEiY/edit#slide=id.g2d63de434db_0_0">slides</a></p>
<p>Our lab received one outstanding paper in ACL 2024 and another in NAACL 2024</p>
<p>Thanks Columbia University for the Provost's Junior Faculty Award 2023</p>
<p>Thanks Sony for the 2023 Faculty Award</p>
<p>Thanks Walmart AI lab for the 2023 Research Award</p>
<p>Thanks Cisco for the 2022 Faculty Award</p>
<p>Thanks IBM for the 2021 IBM Faculty Award</p>
<p>Thanks Adobe for the 2021 Adobe Faculty Award</p>
<p>Thanks Tencent for the 2021 Tencent Faculty Award</p>
<p>Please try our dialog data collection and evaluation tool kit LEGOEval <a href="https://t.co/0PH9ZwSIiD?amp=1">code</a> <a href="https://arxiv.org/pdf/2105.01992.pdf">paper</a> <a href="https://t.co/JMI1YCw9Ph?amp=1">demo</a></p>
<p>I created the first Conversational AI course at Columbia 2021, Here is all the reading materials and corresponding slides.<a href="https://docs.google.com/spreadsheets/d/1nSKcnM5r9x82BdyPgn-obN1sRUlLC7zZ082a0132Igk/edit#gid=1523499517">link</a></p> 
<p> Recent talk at USC ISI, Teaching machines with natural language. <a href="https://www.youtube.com/watch?v=rNyOspG27Xs&amp;t=2230s">video</a> </p>
<p>New WeCNLP invited talk video on Builidng Dialog Systems with Less Supervsion <a href="https://youtu.be/cenK4hwjSPs">video</a></p><p>
</p><p>Recent talk:  Building Dialog Systems with Less Supervision <a href="https://drive.google.com/file/d/1QPAjOO_Ap8odxnint-YXM2bWQZNsEZcT/view?usp=sharing">slides</a></p><p>
</p><p>Recent talk:  Gunrock, 2018 Amazon Alexa Socialbot Winner <a href="https://drive.google.com/file/d/1TUnU-iVmxS-lr5n6_vpMOgOBB5LrPHdE/view?usp=sharing">slides</a></p>
<p>Recent talk:  Grounding Reinforcement Learning with Real-World Dialog Applications <a href="https://drive.google.com/open?id=1HtCj9K4qatc1yJDOdidZV_UTSDDslcNm">slides</a></p>
<!--<p> Here is a YouTube video on Multimodal Dialog Systems at AI2 (Thanks AI2 for the recording) <a href="https://www.youtube.com/watch?v=39T9ukI9HnQ">video</a><p>-->
<p> Here is a Chinese verison of Multimodal Dialog Systems talk that targets to general public. <a href="https://www.youtube.com/watch?v=RrWSetIOR2Q&amp;t=1874s"> video</a></p>
<h3> <font color="orange">News</font> </h3>   
<p> I designed a Conversational AI course in Columbia, here are  the reading materials and slides<a href="https://docs.google.com/spreadsheets/d/1nSKcnM5r9x82BdyPgn-obN1sRUlLC7zZ082a0132Igk/edit?fbclid=IwAR1tX8eztqZ4Kn4NNPUvkkGKCurikWtv-wcSnRyDRg4M544dQtSXTTb3vfM#gid=1523499517">[link]</a></p>
<p><iframe width="560" height="315" src="./www.cs.columbia.edu_files/jIvDJHpi_Lw.html" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>

<p> Our paper Persuasion For Good was nominated for ACL 2019 best paper.</p>
<p> We won Amazon Alexa Prize with $500,000 <a href="https://developer.amazon.com/alexaprize">webpage</a> Please refer to our system report <a href="https://m.media-amazon.com/images/G/01/mobile-apps/dex/alexa/alexaprize/assets/pdf/2018/Gunrock.pdf">[pdf]</a></p>
<p> I was featured on Forbes 30 under 30 in Science <a href="https://www.forbes.com/30-under-30/2018/science/zhou-yu/0">webpage</a> If you want to try our chatbot, just say "Alexa Let's chat!" to any Alexa device or download the App Amazon Alexa on your phone.</p>
<p> If you want to do a PhD with me, please read Mor's advice <a href="https://www.cs.cmu.edu/~harchol/gradschooltalk.pdf">Applying PhD</a>.  </p>
<hr>

<h3><font color="orange"> PhD Students </font></h3>
<p><a href="https://www.linkedin.com/in/mingyang-zhou-9b174650/">Mingyang Zhou</a>, graduated 2022, Now Researcher at Capital One</p>
<p><a href="https://www.linkedin.com/in/dianbyu/">Dian Yu</a>, graduated 2022, Now Researcher at Google Deepmind</p>
<p><a href="https://wyshi.github.io/">Weiyan Shi</a>, graduated 2023, Now Faculty at Northeastern </p>
<p><a href="https://www.linkedin.com/in/sam-davidson-nlp/">Sam Davidson</a>, graduated 2024, Now Applied Scientist at Amazon AWS</p>
<p><a href-"https:="" www.linkedin.com="" in="" qingyang-wu-2497a0110="" "="">Qingyang Wu</a>, graduated 2024, Now Researcher at Together.ai</p>
<p><a href="https://www.linkedin.com/in/kun-qian-6b01b113a/">Kun Qian </a>, graduated 2024, Now Scientist at Apple</p>
<p><a href="https://www.linkedin.com/in/yanda-chen-03455a16a/">Yanda Chen</a>, graduated 2024, Now Researcher at Anthropic </p>
<p><a href="https://yooli23.github.io/"> Yu Li</a> joined 2020 </p>
<p><a href="https://max.imillian.com/"> Max Chen</a>, joined 2021, Graduate Fellowship for STEM Diversity </p>
<p><a href="https://skywang.me/">Sky Wang</a>, joined 2021, NSF Graduate Fellowship </p>
<p><a href="https://www.matoles.com/">Matthew Toles</a>, joined 2022, NSF Graduate Fellowship </p>
<p><a href="https://zacharyhorvitz.github.io/">Zachary Horvitz</a>, joined 2023, Amazon Fellowship </p>
<p><a href="https://siyan-sylvia-li.com/">Siyan(Sylvia) Li</a>, joined 2023 </p>
<p><a href="https://billyzhang24kobe.github.io/">Xuanming Zhang</a>, joined 2023</p>
<p><a href="https://jasonyux.com/">Xiao Yu</a>, joined 2023</p>
<p><a href="https://scholar.google.com/citations?user=S0vGr-gAAAAJ&amp;hl=en">Yunan(Lucy) Lu</a>, joined 2024 </p>

<h3> <font color="orange">Selected Publications </font></h3>
<p>ExACT: Teaching AI Agents to Explore with Reflective-MCTS and Exploratory Learning, Xiao Yu, Baolin Peng, Vineeth Vajipey, Hao Cheng, Michel Galley, Jianfeng Gao, Zhou Yu, arxiv 2024 <a href="https://agent-e3.github.io/ExACT/">website</a></p>
<p>Xiao Yu, Jinzhong Zhang, Zhou Yu ConFit: Improving Resume-Job Matching using Data Augmentation and Contrastive Learning, RecSys 2024</p>
<p>Xiao Yu, Qingyang Wu, Yu Li, Zhou Yu, LIONs: An Empirically Optimized Approach to Align Language Models, EMNLP 2024</p>
<p>Xuanming Zhang, Anthony Diaz, Zixun Chen, Qingyang Wu, Kun Qian, Erik Voss, Zhou Yu, DECOR: Improving Coherence in L2 English Writing with a Novel Benchmark for Incoherence Detection, Reasoning, and Rewriting, EMNLP 2024</p>
<p>Ryan Shea, Aymen Kallala, Xin Lucy Liu, Michael W. Morris, Zhou Yu, ACE: A LLM-based Negotiation Coaching System, EMNLP 2024</p>
<p>Ryan Shea, Zhou Yu, A Fairness-Driven Method for Learning Human-Compatible Negotiation Strategies, EMNLP 2024</p>
<p>Zachary Horvitz, Ajay Patel, Kanishk Singh, Chris Callison-Burch, Kathleen McKeown, Zhou Yu, TinyStyler: Efficient Few-Shot Text Style Transfer with Authorship Embeddings, EMNLP 2024 Findings</p>
<p>Kun Qian, Shunji Wan, Claudia Tang, Youzhi Wang, Xuanming Zhang, Maximillian Chen, Zhou Yu, VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation, EMNLP 2024 Findings</p>
<p>Siyan Li, Teresa Shao, Zhou Yu, Julia Hirschberg, EDEN: Empathetic Dialogues for English Learning, EMNLP 2024 Findings</p>
<p>Yu Li, Shang Qu, Jili Shen, Shangchao Min, Zhou Yu, Curriculum-Driven Edubot: A Framework for Developing Language Learning Chatbots Through Synthesizing Conversational Data SIGDIAL 2024</p>
<p>Yu-Wen Chen, Zhou Yu, Julia Hirschberg, MultiPA: A Multi-task Speech Pronunciation Assessment Model for Open Response Scenarios, INTERSPEECH 2024</p>
<p>Yanda Chen, Ruiqi Zhong, Narutatsu Ri, Chen Zhao, He He, Jacob Steinhardt, Zhou Yu, Kathleen McKeown, Do Models Explain Themselves? Counterfactual Simulatability of Natural Language Explanations, ICML 2024</p>
<p>Yanda Chen, Chen Zhao, Zhou Yu, Kathleen McKeown, He He, Parallel Structures in Pre-training Data Yield In-Context Learning, ACL 2024</p>
<p>Zachary Horvitz, Jingru Chen, Rahul Aditya, Harshvardhan Srivastava, Robert West, Zhou Yu, Kathleen McKeown, Getting Serious about Humor: Crafting Humor Datasets with Unfunny Large Language Models, ACL 2024, Outstanding paper</p>
<p>Xuanming Zhang, Zixun Chen, Zhou Yu, ProLex: A Benchmark for Language Proficiency-oriented Lexical Substitution, ACL 2024 Findings</p>
<p>Myeongseob Ko · Feiyang Kang · Weiyan Shi · Ming Jin · Zhou Yu · Ruoxi Jia, The Mirrored Influence Hypothesis: Efficient Data Influence Estimation by Harnessing Forward Passes, CVPR 2024</p>
<p>Xiao Yu, Baolin Peng, Michel Galley, Jianfeng Gao, Zhou Yu, Teaching Language Models to Self-Improve through Interactive   Demonstrations, NAACL 2024, Outstanding paper </p>
<p>Zachary Horvitz, Ajay Patel, Chris Callison-Burch, Zhou Yu, Kathleen McKeown, ParaGuide: Guided Diffusion Paraphrasers for Plug-and-Play Textual Style Transfer, AAAI 2024</p>
<p>Jianguo Zhang, Kun Qian, Zhiwei Liu, Shelby Heinecke, Rui Meng, Ye Liu, Zhou Yu, Silvio Savarese, Caiming Xiong, DialogStudio: Towards Richest and Most Diverse Unified Dataset Collection for Conversational AI, arxiv 2023</p>
<p>Ryan Shea, Zhou Yu, Building Persona Consistent Dialogue Agents with Offline Reinforcement Learning EMNLP 2023</p>
<p>Xiao Yu, Qingyang Wu, Kun Qian, Zhou Yu, KRLS: Improving End-to-End Response Generation in Task Oriented Dialog with Reinforced Keywords Learning, EMNLP 2023</p>
<p>Libo Qin, Wenbo Pan, Qiguang Chen, Lizi Liao, Zhou Yu, Yue Zhang, Wanxiang Che, Min Li, End-to-end Task-oriented Dialogue: A Survey of Tasks, Methods, and Future Directions, EMNLP 2023</p>
<p>Xiao Yu, Maximillian Chen, Zhou YuPrompt-Based Monte-Carlo Tree Search for Goal-oriented Dialogue Policy Planning, EMNLP 2023</p>
<p>Sky CH-Wang, Arkadiy Saakyan, Oliver Li, Zhou Yu, Smaranda Muresan, Sociocultural Norm Similarities and Differences via Situational Alignment and Explainable Textual Entailment, EMNLP 2023</p>
<p>Rahul Goel, Waleed Ammar, Aditya Gupta, Siddharth Vashishtha, Motoki Sano, Faiz Surani, Max Chang, HyunJeong Choe, David Greene, Chuan He, Rattima Nitisaroj, Anna Trukhina, Shachi Paul, Pararth Shah, Rushin Shah, Zhou Yu, PRESTO: A Multilingual Dataset for Parsing Realistic Task-Oriented Dialogs, EMNLP 2023</p>
<p>Weiyan Shi, Emily Dinan, Adi Renduchintala, Daniel Fried, Athul Paul Jacob, Zhou Yu, Mike Lewis, AutoReply: Detecting Nonsense in Dialogue with Discriminative Replies EMNLP 2023 Findings</p>
<p>Yanda Chen, Chen Zhao, Zhou Yu, Kathleen McKeown, He He, On the Relation between Sensitivity and Accuracy in In-context Learning, EMNLP 2023 Findings</p>
<p>Yukun Huang, Yanda Chen, Zhou Yu, Kathleen McKeown, In-context Learning Distillation: Transferring Few-shot Learning Ability of Pre-trained Language Models AACL 2023</p>
<p>Yohei Hayamizu, Zhou Yu, and Shiqi Zhang, Learning Joint Policies for Human-Robot Dialog and Co-Navigation, IEEE/RSJ International Conference on Intelligent Robots (IROS), 2023 </p>
<p>Qingyang Wu, Zhou Yu, Stateful Memory-Augmented Transformers for Efficient Dialogue Modeling, arxiv 2023, <a href="https://arxiv.org/pdf/2209.07634.pdf">[pdf]</a></p>
<p>Derek Chen, Celine Lee, Yunan Lu, Domenic Rosati, Zhou Yu, Mixture of Soft Prompts for Controllable Data Generation, EMNLP 2023 Findings, <a href="https://arxiv.org/pdf/2303.01580.pdf">[pdf]</a> </p>
<p>Qingyang Wu, Deema Alnuhait, Derek Chen, Zhou Yu, Using Textual Interface to Align External Knowledge for End-to-End Task-Oriented Dialogue Systems,arxiv 2023, <a href="https://arxiv.org/pdf/2305.13710.pdf">[pdf]</a></p>
<p>Maximillian Chen, Xiao Yu, Weiyan Shi, Urvi Awasthi, Zhou Yu Controllable Mixed-Initiative Dialogue Generation through Prompting ACL 2023, <a href="https://arxiv.org/abs/2305.04147">[pdf]</a></p>
<p>Yu Li, Baolin Peng, Pengcheng He, Michel Galley, Zhou Yu, Jianfeng Gao, DIONYSUS: A Pre-trained Model for Low-Resource Dialogue Summarization, ACL 2023, <a href="https://arxiv.org/abs/2212.10018">[pdf]</a></p>
<p>Kun Qian, Ryan Shea, Yu Li, Luke Kutszik Fryer, Zhou Yu, User Adaptive Language Learning Chatbots with a Curriculum, AIED 2023,<a href="https://arxiv.org/pdf/2304.05489.pdf">[pdf]</a></p>
<p>Yanda Chen, Chen Zhao, Zhou Yu, Kathleen McKeown, He He, On the Relation between Sensitivity and Accuracy in In-context Learning, arxiv 2023 <a href="https://arxiv.org/pdf/2209.07661.pdf">[pdf]</a></p>
<p>Max Chen,  Zhou Yu, Pre-Finetuning for Few-Shot Emotional Speech Recognition, Interspeech 2023 <a href="https://arxiv.org/abs/2302.12921">[odf]</a></p>
<p>Yukun Huang, Yanda Chen, Zhou Yu, Kathleen McKeown, In-context Learning Distillation: Transferring Few-shot Learning Ability of Pre-trained Language Models arxiv 2023, <a href="https://arxiv.org/pdf/2212.10670.pdf">[pdf]</a></p>
<p>Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou Yu, Weizhu Chen, Jianfeng Gao, Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback, arXiv 2023 <a href="https://arxiv.org/pdf/2302.12813.pdf">[pdf]</a></p>
<p>Rahul Goel, Waleed Ammar, Aditya Gupta, Siddharth Vashishtha, Motoki Sano, Faiz Surani, Max Chang, HyunJeong Choe, David Greene, Kyle He, Rattima Nitisaroj, Anna Trukhina, Shachi Paul, Pararth Shah, Rushin Shah, Zhou Yu, PRESTO: A Multilingual Dataset for Parsing Realistic Task-Oriented Dialogs, arxiv 2023 <a href="https://arxiv.org/pdf/2303.08954.pdf">[pdf]</a></p>
<p>Maximillian Chen, Caitlyn K. Chen, Xiao Yu and Zhou Yu, FastKASSIM: A Fast Tree Kernel-Based Syntactic Similarity Metric, EACL 2023 <a href="https://arxiv.org/pdf/2203.08299.pdf">[pdf]</a></p>
<p>Kushal Chawla, Weiyan Shi, Jingwen Zhang, Gale Lucas, Zhou Yu and Jonathan Gratch, Social Influence Dialogue Systems: A Survey of Datasets and Models For Social Influence Tasks, EACL 2023 <a href="https://arxiv.org/pdf/2210.05664.pdf">[pdf]</a></p>
<p>Derek Chen, Kun Qian and Zhou Yu, Stabilized In-Context Learning with Pre-trained Language Models for Few Shot Dialogue State Tracking, EACL 2023 Findings <a href="https://arxiv.org/pdf/2302.05932.pdf">[pdf]</a></p>
<p>Maximillian Chen, Alexandros Papangelis, Chenyang Tao, Seokhwan Kim, Andy Rosenbaum, Yang Liu, Zhou Yu and Dilek Hakkani-Tur, PLACES: Prompting Language Models for Social Conversation Synthesis EACL 2023 Findings <a href="https://arxiv.org/pdf/2302.03269.pdf">[pdf]</a></p>
<p>Yingwen Fu, Wenjie Ou, Zhou Yu, and Yue Lin, MIGA: A Unified Multi-task Generation Framework for Conversational Text-to-SQL, AAAI 2023<a href="https://arxiv.org/pdf/2212.09278.pdf">[pdf]</a> </p>
<p>Weiyan Shi, Ryan Patrick Shea, Si Chen, Chiyuan Zhang, Ruoxi Jia and Zhou Yu, Just Fine-tune Twice: Selective Differential Privacy for Large Language Models, EMNLP 2022 <a href="https://arxiv.org/pdf/2204.07667.pdf">[pdf]</a></p>

<p>David Gros, Yu Li and Zhou Yu, Robots-Dont-Cry v1: Understanding Falsely Anthropomorphic Utterances in Dialog Systems, EMNLP 2022<a href="https://arxiv.org/pdf/2210.12429.pdf">[pdf]</a></p>
<p>Sky CH-Wang, Evan Li, Oliver Li, Smaranda Muresan and Zhou Yu, Affective Idiosyncratic Responses to Music, EMNLP 2022 <a href="https://arxiv.org/pdf/2210.09396.pdf">[pdf]</a></p>
<p>Mingyang Zhou, Grace Luo, Anna Rohrbach and Zhou Yu, Focus! Relevant and Sufficient Context Selection for News Image Captioning, EMNLP 2022 Findings <a href="https://arxiv.org/pdf/2212.00843.pdf">[pdf]</a> </p>
<p>Maximillian Chen, Weiyan Shi, Feifan Yan, Ryan Hou, Jingwen Zhang, Saurav Sahay and Zhou Yu, Seamlessly Integrating Factual Information and Social Content with Persuasive Dialogue, AACL 2022 <a href="https://arxiv.org/pdf/2203.07657.pdf"> [pdf]</a></p>
<p>Qingyang Wu, Zhenzhong Lan, Kun Qian, Jing Gu, Alborz Geramifard, Zhou Yu, Memformer: A Memory-Augmented Transformer for Sequence Modeling, AACL Findings 2022 <a href="https://aclanthology.org/2022.findings-aacl.29.pdf">[pdf]</a></p>
<p>Libo Qin, Qiguang Chen, Tianbao Xie, Qian Liu, Shijue Huang, Wanxiang Che and Zhou Yu,CGIM: A Cycle Guided Interactive Learning Model for Consistency Identification in Task-oriented Dialogue, Coling 2022 <a href="https://aclanthology.org/2022.coling-1.37/">[pdf]</a></p>
<p>Lu Sun, Yuhan Liu, Grace Joseph, Yu Zhou, Steven P. Dow and Haiyi Zhu, Comparing experts and crowds for AI data work: allocating human intelligence to design a conversational agent, HCOMP 2022 <a href="https://ojs.aaai.org/index.php/HCOMP/article/view/21999">[pdf]</a></p>

<p>Liang Qiu, Yizhou Zhao, Yuan Liang, Pan Lu, Weiyan Shi, Zhou Yu and Song-Chun Zhu, Towards Socially Intelligent Agents with Mental State Transition and Human Value, SIGDIAL 2022 <a href="https://arxiv.org/pdf/2103.07011.pdf">[pdf]</a></p>
<p>Qingyang Wu, Song Feng, Derek Chen, Sachindra Joshi, Luis Lastras and Zhou Yu, DG2: Data Augmentation Through Document Grounded Dialogue Generation, SIGDIAL 2022</p>
<p>Baolin Peng, Michel Galley, Pengcheng He, Chris Brockett, Lars Liden, Elnaz Nouri, Zhou Yu, Bill Dolan, Jianfeng Gao, GODEL: Large-Scale Pre-Training for Goal-Directed Dialog <a href="https://arxiv.org/abs/2206.11309">[pdf]</a> <a href="https://huggingface.co/microsoft/GODEL-v1_1-large-seq2seq?text=Hey+my+name+is+Thomas%21+How+are+you%3F">[code]</a> <a href="https://www.microsoft.com/en-us/research/blog/godel-combining-goal-oriented-dialog-with-real-world-conversations/">[blog]</a></p>
<p>Weiyan Shi, Aiqi Cui, Evan Li, Ruoxi Jia and Zhou Yu, Selective Differential Privacy for Language Models, NAACL 2022 <a href="https://arxiv.org/abs/2108.12944">[pdf]</a><a href="https://github.com/wyshi/lm_privacy">[code]</a></p>
<p>Yu Li, Baolin Peng, Yelong Shen, Yi Mao, Lars Liden, Zhou Yu, Jianfeng Gao, Knowledge-Grounded Dialogue Generation with a Unified Knowledge Representation, NAACL 2022<a href="https://arxiv.org/abs/2112.07924">[pdf]</a></p>
<p>Kun Qian, Ahmad Beirami, Satwik Kottur, Shahin Shayandeh, Paul Crook, Alborz Geramifard, Zhou Yu, Chinnadhurai Sankar, Database Search Results Disambiguation for Task-Oriented Dialog Systems, NAACL 2022<a href="https://arxiv.org/pdf/2112.08351.pdf">[pdf]</a></p>
<p>Xun Yuan, Sam Pham, Sam Davidson, Zhou Yu, ErAConD: Error Annotated Conversational Dialog Dataset for Grammatical Error Correction, NAACL 2022<a href="https://arxiv.org/abs/2112.08466">[pdf]</a></p>
<p>Mingyang Zhou, Licheng Yu, Amanpreet Singh, Mengjiao Wang, Zhou Yu, Ning Zhang, Unsupervised Vision-and-Language Pre-training via Retrieval-based Multi-Granular Alignment, CVPR 2022 <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Unsupervised_Vision-and-Language_Pre-Training_via_Retrieval-Based_Multi-Granular_Alignment_CVPR_2022_paper.pdf">[pdf]</a></p>
<p>Bowen Yang, Cong Han, Yu Li, Lei Zuo, Zhou Yu, Improving Conversational Recommendation Systems’ Quality with Context-Aware Item Meta-Information, NAACL 2022 Findings <a href="https://arxiv.org/abs/2112.08140">[pdf]</a></p>
<p>Yu Li, Chun-Yen Chen, Dian Yu, Sam Davidson, Ryan Hou, Xun Yuan, Yinghua Tan, Derek Pham, Zhou Yu, Using Chatbots to Teach Languages, Learning at Scale, 2022<a href="https://arxiv.org/pdf/2208.00376.pdf">[pdf]</a></p>
<p>Ying Xu, Dakuo Wang, Mo Yu, Daniel Ritchie, Bingsheng Yao, Tongshuang Wu, Zheng Zhang, Toby Jia-Jun Li, Nora Bradford, Branda Sun, Tran Bao Hoang, Yisi Sang, Yufang Hou, Xiaojuan Ma, Diyi Yang, Nanyun Peng, Zhou Yu, Mark Warschauer, Fantastic Questions and Where to Find Them: FairytaleQA--An Authentic Dataset for Narrative Comprehension, ACL 2022 <a href="https://arxiv.org/abs/2203.13947">[pdf]</a></p>
<p>Yingwen_Fu, Wenjie Ou, Zhou Yu, Yue Lin, Effective Unsupervised Constrained Text Generation based on Perturbed Masking, ACL 2022 Findings <a href="https://aclanthology.org/2022.findings-acl.111.pdf">[pdf]</a></p>
<p>Matthew Marge, Carol Espy-Wilson, Nigel G Ward, Abeer Alwan, Yoav Artzi, Mohit Bansal, Gil Blankenship, Joyce Chai, Hal Daumé III, Debadeepta Dey, Mary Harper, Thomas Howard, Casey Kennington, Ivana Kruijff-Korbayová, Dinesh Manocha, Cynthia Matuszek, Ross Mead, Raymond Mooney, Roger K Moore, Mari Ostendorf, Heather Pon-Barry, Alexander I Rudnicky, Matthias Scheutz, Robert St Amant, Tong Sun, Stefanie Tellex, David Traum and Zhou Yu,  Spoken language interaction with robots: Recommendations for future research, Computer Speech and Language, 2022 <a href="http://users.umiacs.umd.edu/~hal/docs/daume22spoken.pdf">[pdf]</a></p>
<p>Derek Chen and  Zhou Yu, GOLD: Improving Out-of-Scope Detection in Dialogues using Data Augmentation, EMNLP 2021 <a href="https://arxiv.org/abs/2109.03079">[pdf]</a><a href="https://github.com/asappresearch/gold">[code]</a></p>
<p>Andrea Madotto, Zhaojiang Lin, Zhenpeng Zhou, Seungwhan Moon, Paul Crook, Bing Liu, Zhou Yu, Eunjoon Cho, Pascale Fung and Zhiguang Wang, Continual Learning in Task-Oriented Dialogue Systems, EMNLP 2021 <a href="https://arxiv.org/abs/2012.15504">[pdf]</a></p><p>
</p><p>Zhaojiang Lin, Bing Liu, Andrea Madotto, Seungwhan Moon, Zhenpeng Zhou, Paul Crook, Zhiguang Wang, Zhou Yu, Eunjoon Cho, Rajen Subba and Pascale Fung, Zero-Shot Dialogue State Tracking via Cross-Task Transfer, EMNLP 2021 <a href="https://arxiv.org/abs/2109.04655">[pdf]</a></p>
<p>Weiyan Shi, Yu Li, Saurav Sahay and Zhou Yu, Refine and Imitate: Reducing Repetition and Inconsistency in Persuasion Dialogues via Reinforcement Learning and Human Demonstration, EMNLP 2021 Findings <a href="https://arxiv.org/abs/2012.15375">[pdf]</a></p>
<p>Dian Yu, Zhou Yu and Kenji Sagae, Attribute Alignment: Controlling Text Generation from Pre-trained Language Models, EMNLP 2021 Findings <a href="https://arxiv.org/abs/2103.11070"> [pdf]</a></p>
<p>Jun Zhang, Yan Yang, Chencai Chen, liang he and Zhou Yu, KERS: A Knowledge-Enhanced Framework for Recommendation Dialog Systems with Multiple Subgoals, EMNLP 2021 Findings <a href="https://aclanthology.org/2021.findings-emnlp.94/">[pdf]</a></p>
<p>Kai-Hui Liang, Weiyan Shi, Yoojung Oh, Jingwen Zhang, Zhou Yu, Discovering Chatbot's Self-Disclosure's Impact on User Trust, Affinity, and Recommendation Effectiveness, arXiv <a href="https://arxiv.org/abs/2106.01666">[pdf]</a></p>
<p>Kai-Hui Liang, Patrick Lange, Yoo Jung Oh, Jingwen Zhang, Yoshimi Fukuoka and Zhou Yu, Evaluation of In-Person Counseling Strategies To Develop Physical Activity Chatbot for Women, SIGDIAL 2021 <a href="https://arxiv.org/abs/2107.10410">[pdf]</a></p>
<p>Satwik Kottur, Chinnadhurai Sankar, Zhou Yu and Alborz Geramifard, DialogStitch: Synthetic Deeper and Multi-Context Task-Oriented Dialogs, SIGDIAL 2021 <a href="https://aclanthology.org/2021.sigdial-1.3.pdf">[pdf]</a></p>
<p>Minh Nguyen and Zhou Yu, Improving Named Entity Recognition in Spoken Dialog Systems by Context and Speech Pattern Modeling, SIGDIAL 2021 <a href="https://aclanthology.org/2021.sigdial-1.6/">[pdf]</a></p>
<p>Lu Pan, Liang Qiu, Jiaqi Chen, Tony Xia, Yizhou Zhao, Wei Zhang, Zhou Yu, Xiaodan Liang, and Song-Chun Zhu, IconQA: A New Benchmark for Abstract Diagram Understanding and Visual Language Reasoning. NeurIPS 2021, Datasets and Benchmarks Track.<a href="https://openreview.net/pdf?id=uXa9oBDZ9V1">[pdf]</a></p>
<p>Kun Qian, Ahmad Beirami, Zhouhan Lin, Ankita De, Alborz Geramifard, Zhou Yu and Chinnadhurai Sankar, Annotation Inconsistency and Entity Bias in MultiWOZ, SIGDIAL 2021 <a href="https://arxiv.org/abs/2105.14150">[pdf]</a></p>
<p>Jing Gu, Qingyang Wu, Chongruo Wu, Weiyan Shi and Zhou Yu,  PRAL: A Tailored Pre-Training Model for Task-Oriented Dialog Generation,  ACL 2021 <a href="https://arxiv.org/pdf/2004.13835.pdf">[pdf]</a><a href="https://github.com/qywu/PRAL">[code]</a></p>
<p>Vojtěch Hudeček, Ondřej Dušek and Zhou Yu,  Discovering Dialogue Slots with Weak Supervision, ACL 2021 <a href="https://aclanthology.org/2021.acl-long.189.pdf">[pdf]</a></p>
<p>Weixin Liang, Kai-Hui Liang and Zhou Yu, HERALD: An Annotation Efficient Method to Detect User Disengagement in Social Conversations, ACL 2021 <a href="https://arxiv.org/pdf/2106.00162.pdf">[pdf]</a><a href="https://github.com/Weixin-Liang/HERALD/">[code and data]</a><a href="https://drive.google.com/file/d/1xjNUrkmSm-eBEQLBR2UXl2YpXkvz54-2/view?usp=sharing">[video]</a></p>
<p>David Gros, Yu Li and Zhou Yu, The R-U-A-Robot Dataset: Helping Avoid Chatbot Deception by Detecting User Questions About Human or Non-Human Identity, ACL 2021 <a href="https://arxiv.org/pdf/2106.02692.pdf">[pdf]</a><a href="https://github.com/DNGros/R-U-A-Robot">[code and data]</a></p>
<p>Siyang Liu, Chujie Zheng, Orianna Demasi, Sahand Sabour, Yu Li, Zhou Yu, Yong Jiang and Minlie Huang, Towards Emotional Support Dialogue Systems, ACL 2021 <a href="https://arxiv.org/abs/2106.01144">[pdf]</a></p>
<p>Liang Qiu, Yuan Liang, Yizhou Zhao, Pan Lu, Baolin Peng, Zhou Yu, Ying Nian Wu and Song-Chun Zhu, SocAoG: Incremental Graph Parsing for Social Relation Inference in Dialogues, ACL 2021 <a href="https://arxiv.org/pdf/2106.01006.pdf">[pdf]</a> <a href="https://github.com/Liang-Qiu/SocAoG-dialogues">[code]</a></p>
<p>Meng Zhou, Zechen Li, Bowen Tan, Guangtao Zeng, Wenmian Yang, Xuehai He, Zeqian Ju, Subrato Chakravorty, Shu Chen, Xingyi Yang, Yichen Zhang, Qingyang Wu, Zhou Yu, Kun Xu, Eric Xing and Pengtao Xie, On the Generation of Medical Dialogs for COVID-19, ACL 2021 <a href="https://arxiv.org/pdf/2005.05442.pdf">[pdf]</a> <a href="https://github.com/UCSD-AI4H/COVID-Dialogue">[code and data]</a></p>
<p> Derek Chen, Howard Chen, Yi Yang, Alexander Lin and Zhou Yu, Action-Based Conversations Dataset:A Corpus for Building More In-Depth Task-Oriented Dialogue Systems, NAACL 2021 <a href="https://arxiv.org/pdf/2104.00783.pdf">[pdf]</a> <a href="https://github.com/asappresearch/abcd">[code and data]</a></p>
<p>Zhaojiang Lin, Bing Liu, Seungwhan Moon, Paul Crook, Zhenpeng Zhou, Zhiguang Wang, Zhou Yu, Andrea Madotto, Eunjoon Cho, Rajen Subba, Leveraging Slot Descriptions for Zero-Shot Cross-Domain Dialogue State Tracking, NAACL 2021 <a href="https://arxiv.org/pdf/2105.04222.pdf">[pdf]</a> </p>
<p>Mingyang Zhou, Luowei Zhou, Yu Cheng, Linjie Li, Zhou Yu, Jingjing Liu, UC2: Universal Cross-lingual Cross-modal Vision-and-Language Pretraining, CVPR 2021 <a href="https://arxiv.org/pdf/2104.00332.pdf">[pdf]</a> <a href="https://drive.google.com/file/d/1tWWA_dXOtywgcKiwn4CTxEwers6NN_hW/view?usp=sharing">[video]</a><a href="https://github.com/zmykevin/UC2">[code and data]</a></p>
<p>Qingyang Wu, Lei Li and Zhou Yu, TextGAIL: Generative Adversarial Imitation Learning for Text Generation, AAAI 2021 <a href="https://arxiv.org/pdf/2004.13796.pdf">[pdf]</a><a href="https://github.com/qywu/TextGAIL">[code]</a></p>
<p>Jing Gu, Qingyang Wu and Zhou Yu, Perception Score: A Learned Metric for Open-ended Text Generation Evaluation, AAAI 2021<a href="https://ojs.aaai.org/index.php/AAAI/article/view/17526">[pdf]</a><a href="https://github.com/g-jing/perception-score"></a></p>
<p>Kun Qian, Wei Wei and  Zhou Yu, A Student-Teacher Architecture for Dialog Domain Adaptation under the Meta-Learning Setting. AAAI 2021<a href="https://arxiv.org/pdf/2104.02689.pdf">[pdf]</a><a href="https://github.com/qbetterk/LossAttention">[code]</a></p>
<p>Jing Gu, Mostafa Mirshekari, Zhou Yu and Aaron Sisto,  ChainCQG: Flow-Aware Conversational Question Generation, EACL 2021 <a href="https://arxiv.org/pdf/2102.02864.pdf">[pdf]</a><a href="https://github.com/g-jing/Chain-CQG">[code]</a></p>
<p>Qingyang Wu, Yichi Zhang, Yu Li and Zhou Yu,  Alternating Recurrent Dialog Model with Large-scale Pre-trained Language Models, EACL 2021 <a href="https://www.aclweb.org/anthology/2021.eacl-main.110.pdf">[pdf]</a><a href="https://github.com/qywu/ARDM">[code]</a></p>
<p>Dian Yu and Zhou Yu, MIDAS: A Dialog Act Annotation Scheme for Open Domain Human Machine Spoken Conversations, EACL 2021 <a href="https://arxiv.org/pdf/1908.10023.pdf">[pdf]</a><a href="https://github.com/DianDYu/MIDAS_dialog_act">[code]</a></p>
<p>David Gros, Hariharan Sezhiyan, Prem Devanbu, Zhou Yu, Code to Comment "Translation": Data, Metrics, Baselining &amp; Evaluation, ASE 2020 <a href="https://www.cs.ucdavis.edu/~devanbu/code_comm_trans.pdf">[pdf]</a> </p>
<p>Shirley Anugrah Hayati, Dongyeop Kang, Qingxiaoyang Zhu, Weiyan Shi and Zhou Yu, INSPIRED: Toward Sociable Recommendation Dialog Systems. EMNLP 2020 <a href="https://arxiv.org/abs/2009.14306">[pdf]</a><a href="https://github.com/sweetpeach/Inspired">[code and data]</a></p>
<p>Liang Qiu, Yizhou Zhao, Weiyan Shi, Yuan Liang, Feng Shi, Tao Yuan, Zhou Yu, Song-Chun Zhu, Structured Attention for Unsupervised Dialogue Structure Induction, EMNLP 2020 <a href="https://arxiv.org/abs/2009.08552">[pdf]</a></p>
<p>Orianna Demasi, Yu Li, Zhou Yu, A Multi-Persona Chatbot for Hotline Counselor Training, Findings in EMNLP 2020, <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.324.pdf">[pdf]</a></p>
<p>Weixin Liang, James Zou and Zhou Yu, ALICE: Active Learning with Contrastive Natural Language Explanations, EMNLP 2020 <a href="https://arxiv.org/abs/2009.10259">[pdf]</a></p>
<p>Weixin Liang, James Zou and Zhou Yu, Beyond User Self-Reported Likert Scale Ratings: A Comparison Model for Automatic Dialog Evaluation, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.126.pdf">[pdf]</a></p>
<p>Silin Gao, Yichi Zhang, Zhijian Ou and Zhou Yu, Paraphrase Augmented Task-Oriented Dialog Generation, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.60.pdf">[pdf]</a></p>
<p>Jiaying Hu, Yan Yang, Chencai Chen, Liang He and Zhou Yu, SAS: Dialogue State Tracking via Slot Attention and Slot Information Sharing, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.567.pdf">[pdf]</a></p>
<p>Yiheng Zhou, Yulia Tsvetkov, Alan Black, and Zhou Yu,  Augmenting Non-Collaborative Dialog Systems with Explicit Semantic and Strategic Dialog History, ICLR 2020, <a href="https://arxiv.org/abs/1909.13425">[pdf]</a></p>
<p>Weiyan Shi, Yoo Jung Oh,  Xuewei Wang, Saurav Sahay, Jingwen Zhang, and Zhou Yu, Effects of Persuasive Dialogues: Testing Bot Identities and Inquiry Strategies, CHI 2020 <a href="https://arxiv.org/pdf/2001.04564.pdf">[pdf]</a></p>
<p>Qingyang Wu, Lei Li, Hao Zhou, Ying Zeng and Zhou Yu, Importance-Aware Learning for Neural Headline Editing, AAAI 2020 <a href="https://arxiv.org/pdf/1912.01114.pdf">[pdf]</a></p>
<p>Yu Li, Kun Qian, Weiyan Shi and Zhou Yu, End-to-End Trainable Non-Collaborative Dialog System, AAAI 2020 <a href="https://arxiv.org/pdf/1911.10742.pdf">[pdf]</a></p>
<p>Xiyuan Zhang, Chenxi Li, Sam Davidson, Dian Yu and Zhou Yu, Filling Conversation Ellipsis for Better Social Dialog Understanding, AAAI 2020 <a href="https://arxiv.org/pdf/1911.10776.pdf">[pdf]</a></p>
<p>Weixin Liang, Youzhi Tian, Chengcai Chen and Zhou Yu, MOSS: End-to-End Dialog System Framework with Modular Supervision, AAAI 2020 <a href="https://arxiv.org/abs/1909.05528">[pdf]</a></p>
<p>Yichi Zhang, Zhijian Ou and  Zhou Yu, Task-Oriented Dialog Systems that Consider Multiple Appropriate Responses under the Same Context, AAAI 2020 <a href="https://arxiv.org/pdf/1911.10484.pdf">[pdf]</a> <a href="https://gitlab.com/ucdavisnlp/damd-multiwoz">[code]</a></p>
<p>Dian Yu &amp; Zhou Yu, MIDAS: A Dialog Act Annotation Scheme for Open Domain Human Machine Spoken Conversations, arXiv <a href="https://arxiv.org/abs/1908.10023">[pdf]</a></p>
<p>Mingyang Zhou, Joshua Arnold, Zhou Yu, Building Task-Oriented Visual Dialog Systems Through Alternative Optimization Between Dialog Policy and Language Generation, EMNLP 2019 <a href="https://arxiv.org/abs/1909.05365">[pdf]</a></p>
<p>Weiyan Shi, Kun Qian, Xuewei Wang, Zhou Yu, How to Build User Simulators to Train RL-based Dialog Systems, EMNLP 2019 <a href="http://arxiv.org/abs/1909.01388">[pdf]</a></p>
<p>Sam Davidson, Dian Yu, Zhou Yu, Dependency Parsing for Spoken Dialog Systems, EMNLP 2019 <a href="http://arxiv.org/abs/1909.03317">[pdf]</a></p>
<p>Dian Yu, et al., Gunrock: A Social Bot for Complex and Engaging Long Conversations, EMNLP 2019 demo <a href="https://arxiv.org/pdf/1910.03042.pdf">[pdf]</a></p>
<p>Michelle Cohn, Chun-Yen Chen and Zhou Yu, A Large-Scale User Study of an Alexa Prize Chatbot: Effect of TTS Dynamism on Perceived Quality of Social Dialog, SIGDIAL 2019 <a href="https://www.researchgate.net/publication/336241774_A_Large-Scale_User_Study_of_an_Alexa_Prize_Chatbot_Effect_of_TTS_Dynamism_on_Perceived_Quality_of_Social_Dialog">[pdf]</a></p>
<p>Kun Qian &amp; Zhou Yu, Domain Adaptive Dialog Generation via Meta Learning, ACL 2019 <a href="https://arxiv.org/pdf/1906.03520.pdf">[pdf]</a></p>
<p>Xuewei Wang, Weiyan Shi, Richard Kim, Yoo Jung Oh, Sijia Yang, Jingwen Zhang, Zhou Yu, Persuasion for Good: Towards a Personalized Persuasive Dialogue System for Social Good, ACL 2019<a href="https://arxiv.org/pdf/1906.06725.pdf">[pdf]</a>, <a href="https://gitlab.com/ucdavisnlp/persuasionforgood">[data and code]</a> ** best paper nomination</p>
<p>Weiyan Shi, Tiancheng Zhao, Zhou Yu, Unsupervised Dialog Structure Learning, NAACL 2019 <a href="https://ariv.org/pdf/1904.03736.pdf">[pdf]</a></p>
<p>Chen et al., Gunrock: Building A Human-Like Social Bot By Leveraging Large Scale Real User Data <a href="https://m.media-amazon.com/images/G/01/mobile-apps/dex/alexa/alexaprize/assets/pdf/2018/Gunrock.pdf">[pdf]</a></p>

<p>Jiaao Chen, Jianshu Chen and Zhou Yu, Incorporating Structured Commonsense Knowledge in Story Completion, AAAI 2019 <a href="http://arxiv.org/abs/1811.00625">[pdf]</a></p>
<p>Youzhi Tian, Zhiting Hu and Zhou Yu, Structured Content Preservation for Unsupervised Text Style Transfer, arXiv 2018 <a href="https://arxiv.org/abs/1810.06526">[pdf]</a></p>
<p>Zijie Zhu, Xuewei Wang, Aakaash Kapoor, Tingrui Pan and Zhou Yu, EIS: A Wearable Device for Epidermal American Sign Language Recognition, IMWUT 2018 (Ubicomp 2019)<a href="https://dl.acm.org/citation.cfm?id=3287080">[pdf]</a></p><p>
</p><p>Mingyang Zhou, Runxiang Cheng, Yong Jae Lee and Zhou Yu, A Visual Attention Grounding Neural Model for Multimodal Machine Translation, EMNLP 2018 <a href="http://aclweb.org/anthology/D18-1400">[pdf]</a><a href="https://github.com/sampalomad/IKEA-Dataset">[data]</a></p>
<p>Weiming Wen, Songwen Su and Zhou Yu, Cross-Lingual Cross-Platform Rumor Verification Pivoting on Multimedia Content, EMNLP 2018 <a href="http://aclweb.org/anthology/D18-1385">[pdf]</a> <a href="https://github.com/WeimingWen/CCRV">[code&amp;data]</a></p>
<p>Jiaping Zhang, Tiancheng Zhao and Zhou Yu, Multimodal Hierarchical Reinforcement Learning Policy for Task-Oriented Visual Dialog, SIGDIAL 2018 <a href="https://arxiv.org/abs/1805.03257">[pdf]</a></p>
<p>Weiyan Shi and Zhou Yu, Sentiment Adaptive End-to-End Dialog Systems, ACL 2018 <a href="https://arxiv.org/abs/1804.10731">[pdf]</a></p>
<p>Ryant et al., Enhancement and Analysis of Conversational Speech: JSALT 2017, ICAASP 2018 <a href="http://languagelog.ldc.upenn.edu/myl/ICASSP_JSALT_2018.pdf">[pdf]</a></p>
<p>Zhou Yu, Alan W Black and Alexander I. Rudnicky, Learning Conversational Systems that Interleave Task and Non-Task Content, IJCAI 2017 <a href="https://arxiv.org/abs/1703.00099">[pdf]</a></p>
<!--p>-Zhou Yu, Xinrui He, Alan W Black and Alexander I. Rudnicky, User Engagement Modeling in Virtual Agents Under Different Cultural Contexts, IVA 2016. </p>-->
<p>Zhou Yu, Vikram Ramanarayanan, Patrick Lange, and David Suendermann-Oeft.  An open-source multimodal dialog system with real-time engagement tracking for job interview trainingapplications.In IWSDS, 2017 <a href="https://www.uni-ulm.de/fileadmin/website_uni_ulm/iui.iwsds2017/papers/IWSDS2017_paper_30.pdf">[pdf]</a></p>
<p>Zhou Yu, Ziyu Xu, Alan W Black and Alexander Rudnicky, Strategy and Policy Learning for Non-Task-Oriented Conversational Systems, SIGDIAL 2016. <a href="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/SigDial_2016.pdf">[pdf]</a></p>
<p>Zhou Yu, Leah Nicolich-Henkin, Alan W Black and Alexander Rudnicky, A Wizard-of-Oz Study on A Non-Task-Oriented Dialog Systems that Reacts to User Engagement, SIGDIAL 2016. <a href="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/SigDial_2016_2.pdf">[pdf]</a></p>
<!--p>Zhou Yu, Ziyu Xu, Alan W Black and Alexander Rudnicky, Chatbot evaluation and database expansion via crowdsourcing, In Proceedings of the RE-WOCHAT workshop of LREC, 2016. <a href = "http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/LREC.pdf">[pdf]</a></p>-->
<p>Sean Andrist, Dan Bohus, Zhou Yu, Eric Horvitz, Are You Messing with Me?: Querying about the Sincerity of Interactions in the Open World. HRI 2016. <a href="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/HRI2015.pdf">[pdf]</a></p>
<!--<p>Zhou Yu, Vikram Ramanarayanan, Robert Mundkowsky, Patrick Lange, Alan Black, Alexei Ivanov, David Suendermann-Oeft, Multimodal HALEF: An Open-Source Modular Web-Based Multimodal HAL, IWSDS 2016. <a href = "http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/IWSDS_ZHOU.pdf">[pdf]</a><p> 
<p>Alexei Ivanov, Patrick Lange, David Suendermann-Oeft, Vikram Ramanarayanan, Yao Qian, Zhou Yu and Jidong Tao, Speed vs. Accuracy: Designing an Optimal ASR System for Spontaneous Non-Native Speech in a Real-Time Application, IWSDS 2016. <a href = "http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/IWSDS_ALEX.pdf">[pdf]</a></p>    
<p>Zhou Yu, Vikram Ramanarayanan, David Suendermann-Oeft, Xinhao Wang, Klaus Zechner, Lei Chen, Jidong Tao and Yao Qian, Using Bidirectional LSTM Recurrent Neural Networks to Learn High-Level Abstractions of Sequential Features for Automated Scoring of Non-Native Spontaneous Speech, ASRU 2015. <a href = "http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/ASRU.pdf">[pdf]</a></p>-->	
<p>Zhou Yu, Dan Bohus and Eric Horvitz, Incremental Coordination: Attention-Centric Speech Production in a Physically Situated Conversational Agent, SIGDIAL 2015. <a href="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/sigdial2015_camera_Zhou_et_al.pdf">[pdf]</a></p><p>
<!--<p>Zhou Yu, Alexandros Papangelis, Alexander Rudnicky, TickTock: Engagement Awareness in a non-Goal-Oriented Multimodal Dialogue System, AAAI Spring Symposium on Turn-taking and Coordination in Human-Machine Interaction 2015. <a href="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/TickTock.pdf">[pdf]</a><a href="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/AAAI_slides.pptx">[slides]</a> <p>
<p>Zhou Yu, Stefan Scherer, David Devault, Jonathan Gratch, Giota Stratou, Louis-Philippe Morency and Justine Cassell, Multimodal Prediction of Psychological Disorder: Learning Verbal and Nonverbal Commonality in Adjacency Pairs, SEMDIAL 2013. <a href="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/semdial_2013_zhou.pdf">[pdf]</a> <a href="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/SEMDIAL_slides.pptx">[slides]</a> <p>
<P>Zhou Yu, David Gerritsen, Amy Ogan, Alan W Black, Justine Cassell, Automatic Prediction of Friendship via Multi-model Dyadic Features, SIGDIAL, 2013. <a href="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/Sigdial2013.pdf">[pdf]</a><p>-->
<!---<p>- Zhou Yu, Deng Cai, Xiaofei He, Error-correcting Output Hashing in Fast Similar Search, <b>Best paper</b> in The Second International Conference on Internet Multimedia Computing and Service, ICIMCS  Harbin, China,Dec.2010. <a href="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/p7-yu.pdf">[pdf]</a>  </p>-->

</p><hr>
<h3> <font color="orange">Demo Videos </font></h3>
<p><b><font color="#01A9DB">TickTock: a multimodal chatbot with user engagement coordination </font></b>
<br><em> - below is a demo of using automatically generated conversational strategy to improve user engagement.</em></p>
<p> <video style="border-color:black;border-style:solid;border-width:thin" width="500" height="400" controls="" poster="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/Engaged.png"><source src="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/Engaged.mp4" type="video/mp4"> </video></p>
<p><b><font color="#01A9DB">Direction-giving Robot: a direction-giving humanoid robot with user attention coordination </font></b>
<br><em> - below is a demo and some real user cases of people interacting with the robot.</em></p>
<p> <video style="border-color:black;border-style:solid;border-width:thin" width="640" height="338" controls="" poster="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/SigDial2015_full.jpg"><source src="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/SigDial2015_full.mp4" type="video/mp4"> </video></p>
<p><b><font color="#01A9DB">HALEF: a distributed web-based multimodal dialog system with user engagement coordination</font></b>
<br><em> - below is a demo of a Amazon Turker interacting with our job interview training application via a web browser. It live-streams videos from usrs' local webcam to the server. </em></p>  
<p> <video style="border-color:black;border-style:solid;border-width:thin" width="640" height="480" controls="" poster="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/EngTask.png">
    <source src="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/EngTask.mp4" type="video/mp4"> </video></p>                         
<hr>
</div>
</div>
</div>
<!--
<div
    id="chat-window"
    botID="NY3C2t6RxmEsMKX3jWCvUmL"
    version="v1alpha1"
    institutionID="richtech"
></div>
-->

  <script defer="">
    const link = document.querySelector('link[data-href="dynamic-stylesheet"]');
    link.href = 'https://d24t34cstvp7ab.cloudfront.net/qa-js-prod/main.css' + '?v=' + Date.now();
      var script = document.createElement('script');
      script.onerror = function() {
        alert('Could not load ' + this.src);
      };
      script.defer = true;
      script.src = 'https://d24t34cstvp7ab.cloudfront.net/qa-js-prod/main.js' + '?v=' + Date.now();
      document.body.appendChild(script);
  </script><script defer="" src="./www.cs.columbia.edu_files/main.js"></script>


<iframe scrolling="no" frameborder="0" allowtransparency="true" src="./www.cs.columbia.edu_files/widget_iframe.2f70fb173b9000da126c79afe2098f02.html" title="Twitter settings iframe" style="display: none;"></iframe><iframe id="rufous-sandbox" scrolling="no" frameborder="0" allowtransparency="true" allowfullscreen="true" style="position: absolute; visibility: hidden; display: none; width: 0px; height: 0px; padding: 0px; border: none;" title="Twitter analytics iframe" src="./www.cs.columbia.edu_files/saved_resource.html"></iframe></body></html>